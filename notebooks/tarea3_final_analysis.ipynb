{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 3: Muestreo MCMC vs Simulaci√≥n Perfecta aplicadas al Modelo de Ising\n",
    "\n",
    "**Cadenas de Markov y Aplicaciones (2025-II)**  \n",
    "**Profesor:** Freddy Hern√°ndez-Romero\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "Este notebook presenta el an√°lisis completo de los resultados experimentales comparando:\n",
    "\n",
    "- **a) Muestreo MCMC**: Algoritmo Metropolis-Hastings (100 muestras aproximadas)\n",
    "- **b) Muestreo Perfecto**: Algoritmo Propp-Wilson (100 muestras exactas)\n",
    "\n",
    "Aplicados al **Modelo de Ising** en lattices K√óK con 10 ‚â§ K ‚â§ 20.\n",
    "\n",
    "## Par√°metros del Experimento\n",
    "\n",
    "- **Tama√±os de lattice**: 10√ó10, 15√ó15, 20√ó20\n",
    "- **Temperaturas inversas Œ≤**: {0, 0.1, 0.2, ..., 0.9, 1.0}\n",
    "- **Distribuci√≥n de Gibbs**: œÄ_Œ≤(Œ∑) = (1/Z_Œ≤)e^(-Œ≤H(Œ∑))\n",
    "- **Hamiltoniano**: H(Œ∑) = -‚àë_{‚ü®x,y‚ü©} Œ∑_x Œ∑_y (J=1, B=0)\n",
    "- **Magnetizaci√≥n**: M(Œ∑) = (1/|V_K|) ‚àë_{x‚ààV_K} Œ∑_x\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrespl/anaconda3/lib/python3.13/site-packages/numpy/_core/getlimits.py:548: UserWarning: Signature b'\\x00\\xd0\\xcc\\xcc\\xcc\\xcc\\xcc\\xcc\\xfb\\xbf\\x00\\x00\\x00\\x00\\x00\\x00' for <class 'numpy.longdouble'> does not match any known type: falling back to type probe function.\n",
      "This warnings indicates broken support for the dtype!\n",
      "  machar = _get_machar(dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Librer√≠as importadas exitosamente\n"
     ]
    }
   ],
   "source": [
    "# Importar librer√≠as necesarias\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar matplotlib\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "\n",
    "print(\"‚úì Librer√≠as importadas exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga y Procesamiento de Resultados\n",
    "\n",
    "Los experimentos ya fueron ejecutados y los resultados est√°n guardados en `ising_results_optimized.pkl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úó Error: Archivo de resultados no encontrado\n",
      "   Ejecute primero: python ising_sampling_optimized.py\n"
     ]
    }
   ],
   "source": [
    "# Cargar resultados completos\n",
    "def load_results():\n",
    "    \"\"\"Cargar resultados del experimento completo\"\"\"\n",
    "    try:\n",
    "        with open('ising_results_optimized.pkl', 'rb') as f:\n",
    "            results = pickle.load(f)\n",
    "        print(\"‚úì Resultados cargados exitosamente\")\n",
    "        return results\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚úó Error: Archivo de resultados no encontrado\")\n",
    "        print(\"   Ejecute primero: python ising_sampling_optimized.py\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error al cargar: {e}\")\n",
    "        return None\n",
    "\n",
    "results = load_results()\n",
    "\n",
    "if results:\n",
    "    # Mostrar par√°metros del experimento\n",
    "    params = results['parameters']\n",
    "    print(f\"\\nüìã PAR√ÅMETROS DEL EXPERIMENTO:\")\n",
    "    print(f\"   ‚Ä¢ Lattice sizes: {params['lattice_sizes']}\")\n",
    "    print(f\"   ‚Ä¢ Beta values: {params['beta_values']}\")\n",
    "    print(f\"   ‚Ä¢ Muestras por configuraci√≥n: {params['n_samples']}\")\n",
    "    print(f\"   ‚Ä¢ Pasos Metropolis-Hastings: {params['mh_steps']:,}\")\n",
    "    print(f\"   ‚Ä¢ J = {params['J']}, B = {params['B']}\")\n",
    "    \n",
    "    total_configs = len(params['lattice_sizes']) * len(params['beta_values'])\n",
    "    total_samples = total_configs * params['n_samples'] * 2\n",
    "    print(f\"\\nüìä TOTAL DE SIMULACIONES: {total_samples:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extracci√≥n y An√°lisis de Datos de Magnetizaci√≥n\n",
    "\n",
    "### c) Estimaci√≥n de la Magnetizaci√≥n E[M(Œ∑)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_magnetization_analysis(results):\n",
    "    \"\"\"Extrae y analiza datos de magnetizaci√≥n\"\"\"\n",
    "    \n",
    "    if results is None:\n",
    "        return None\n",
    "    \n",
    "    sizes = results['parameters']['lattice_sizes']\n",
    "    betas = results['parameters']['beta_values']\n",
    "    \n",
    "    # Estructura para almacenar an√°lisis\n",
    "    analysis_data = []\n",
    "    \n",
    "    for size in sizes:\n",
    "        for beta in betas:\n",
    "            # Datos Metropolis-Hastings\n",
    "            mh_samples = results['metropolis_hastings'][size][beta]['samples']\n",
    "            mh_time = results['metropolis_hastings'][size][beta]['computation_time']\n",
    "            \n",
    "            mh_magnetizations = np.array([s['magnetization'] for s in mh_samples])\n",
    "            mh_energies = np.array([s['energy'] for s in mh_samples])\n",
    "            \n",
    "            # Normalizar por tama√±o del lattice\n",
    "            mh_normalized = mh_magnetizations / (size * size)\n",
    "            \n",
    "            # Datos Propp-Wilson\n",
    "            pw_samples = results['propp_wilson'][size][beta]['samples']\n",
    "            pw_time = results['propp_wilson'][size][beta]['computation_time']\n",
    "            \n",
    "            pw_magnetizations = np.array([s['magnetization'] for s in pw_samples])\n",
    "            pw_energies = np.array([s['energy'] for s in pw_samples])\n",
    "            \n",
    "            # Normalizar por tama√±o del lattice\n",
    "            pw_normalized = pw_magnetizations / (size * size)\n",
    "            \n",
    "            # Almacenar an√°lisis\n",
    "            analysis_data.append({\n",
    "                'size': size,\n",
    "                'beta': beta,\n",
    "                'method': 'Metropolis-Hastings',\n",
    "                'E_M': np.mean(mh_magnetizations),  # E[M(Œ∑)]\n",
    "                'E_M_normalized': np.mean(mh_normalized),  # E[M(Œ∑)] normalizada\n",
    "                'E_abs_M': np.mean(np.abs(mh_magnetizations)),  # E[|M(Œ∑)|]\n",
    "                'E_abs_M_normalized': np.mean(np.abs(mh_normalized)),  # E[|M(Œ∑)|] normalizada\n",
    "                'std_M': np.std(mh_magnetizations),\n",
    "                'E_energy': np.mean(mh_energies),\n",
    "                'std_energy': np.std(mh_energies),\n",
    "                'computation_time': mh_time,\n",
    "                'avg_time_per_sample': mh_time / len(mh_samples)\n",
    "            })\n",
    "            \n",
    "            analysis_data.append({\n",
    "                'size': size,\n",
    "                'beta': beta,\n",
    "                'method': 'Propp-Wilson',\n",
    "                'E_M': np.mean(pw_magnetizations),  # E[M(Œ∑)]\n",
    "                'E_M_normalized': np.mean(pw_normalized),  # E[M(Œ∑)] normalizada\n",
    "                'E_abs_M': np.mean(np.abs(pw_magnetizations)),  # E[|M(Œ∑)|]\n",
    "                'E_abs_M_normalized': np.mean(np.abs(pw_normalized)),  # E[|M(Œ∑)|] normalizada\n",
    "                'std_M': np.std(pw_magnetizations),\n",
    "                'E_energy': np.mean(pw_energies),\n",
    "                'std_energy': np.std(pw_energies),\n",
    "                'computation_time': pw_time,\n",
    "                'avg_time_per_sample': pw_time / len(pw_samples)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(analysis_data)\n",
    "\n",
    "# Extraer datos\n",
    "df_analysis = extract_magnetization_analysis(results)\n",
    "\n",
    "if df_analysis is not None:\n",
    "    print(\"‚úì Datos de magnetizaci√≥n extra√≠dos\")\n",
    "    print(f\"   Total de configuraciones analizadas: {len(df_analysis)}\")\n",
    "    \n",
    "    # Mostrar primeras filas como ejemplo\n",
    "    print(\"\\nüìã MUESTRA DE DATOS EXTRA√çDOS:\")\n",
    "    display(df_analysis.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gr√°fica Principal: Comparaci√≥n de Estimaciones de Magnetizaci√≥n\n",
    "\n",
    "**Gr√°fica requerida por la tarea**: Comparaci√≥n de las estimaciones de magnetizaci√≥n obtenidas en (a) y (b) en funci√≥n de Œ≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hay datos para la gr√°fica\n"
     ]
    }
   ],
   "source": [
    "def create_main_comparison_plot(df_analysis, results):\n",
    "    \"\"\"Crea la gr√°fica principal de comparaci√≥n requerida por la tarea\"\"\"\n",
    "    \n",
    "    if df_analysis is None or results is None:\n",
    "        print(\"No hay datos para la gr√°fica\")\n",
    "        return\n",
    "    \n",
    "    sizes = results['parameters']['lattice_sizes']\n",
    "    betas = np.array(results['parameters']['beta_values'])\n",
    "    \n",
    "    # Crear figura principal\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Configurar colores para diferentes tama√±os\n",
    "    colors = plt.cm.viridis(np.linspace(0.2, 0.9, len(sizes)))\n",
    "    \n",
    "    # Gr√°fica de E[|M(Œ∑)|] vs Œ≤\n",
    "    for i, size in enumerate(sizes):\n",
    "        # Datos Metropolis-Hastings\n",
    "        mh_data = df_analysis[(df_analysis['size'] == size) & (df_analysis['method'] == 'Metropolis-Hastings')]\n",
    "        # Datos Propp-Wilson\n",
    "        pw_data = df_analysis[(df_analysis['size'] == size) & (df_analysis['method'] == 'Propp-Wilson')]\n",
    "        \n",
    "        # Plotear l√≠neas para cada m√©todo\n",
    "        plt.plot(mh_data['beta'], mh_data['E_abs_M_normalized'], \n",
    "                'o-', color=colors[i], label=f'MH {size}√ó{size}', \n",
    "                linewidth=2.5, markersize=7, alpha=0.8)\n",
    "        \n",
    "        plt.plot(pw_data['beta'], pw_data['E_abs_M_normalized'], \n",
    "                's--', color=colors[i], label=f'PW {size}√ó{size}', \n",
    "                linewidth=2.5, markersize=7, alpha=0.8)\n",
    "    \n",
    "    # Temperatura cr√≠tica te√≥rica\n",
    "    beta_c = 2 / np.log(1 + np.sqrt(2))\n",
    "    plt.axvline(beta_c, color='red', linestyle=':', linewidth=2, alpha=0.8,\n",
    "                label=f'Œ≤c te√≥rico ‚âà {beta_c:.3f}')\n",
    "    \n",
    "    # Configurar gr√°fica\n",
    "    plt.xlabel('Œ≤ (temperatura inversa)', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('E[|M(Œ∑)|] normalizada', fontsize=14, fontweight='bold')\n",
    "    plt.title('Tarea 3: Comparaci√≥n de Estimaciones de Magnetizaci√≥n\\n' +\n",
    "              'Muestreo MCMC (Metropolis-Hastings) vs Simulaci√≥n Perfecta (Propp-Wilson)',\n",
    "              fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=11)\n",
    "    plt.grid(True, alpha=0.4)\n",
    "    plt.xlim(-0.05, 1.05)\n",
    "    plt.ylim(-0.05, 1.05)\n",
    "    \n",
    "    # A√±adir texto explicativo\n",
    "    plt.text(0.02, 0.98, \n",
    "             'L√≠neas s√≥lidas: Metropolis-Hastings (MCMC)\\n' +\n",
    "             'L√≠neas punteadas: Propp-Wilson (Perfect Sampling)',\n",
    "             transform=plt.gca().transAxes, fontsize=10,\n",
    "             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('tarea3_magnetization_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úì Gr√°fica principal guardada como 'tarea3_magnetization_comparison.png'\")\n",
    "\n",
    "# Crear gr√°fica principal\n",
    "create_main_comparison_plot(df_analysis, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reporte de Tiempos de Coalescencia\n",
    "\n",
    "**An√°lisis de tiempos de coalescencia observados en Propp-Wilson para cada valor de Œ≤.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_coalescence_times(df_analysis, results):\n",
    "    \"\"\"Analiza tiempos de coalescencia de Propp-Wilson\"\"\"\n",
    "    \n",
    "    if df_analysis is None or results is None:\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"REPORTE DE TIEMPOS DE COALESCENCIA (PROPP-WILSON)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    sizes = results['parameters']['lattice_sizes']\n",
    "    betas = results['parameters']['beta_values']\n",
    "    \n",
    "    # Tabla de resultados\n",
    "    coalescence_summary = []\n",
    "    \n",
    "    for size in sizes:\n",
    "        print(f\"\\nüîó LATTICE {size}√ó{size}:\")\n",
    "        print(f\"{'Œ≤':<6} {'Tiempo Total':<14} {'Tiempo/Muestra':<16} {'Muestras':<10}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        pw_data = df_analysis[(df_analysis['size'] == size) & (df_analysis['method'] == 'Propp-Wilson')]\n",
    "        \n",
    "        for _, row in pw_data.iterrows():\n",
    "            beta = row['beta']\n",
    "            total_time = row['computation_time']\n",
    "            avg_time = row['avg_time_per_sample']\n",
    "            \n",
    "            print(f\"{beta:<6.1f} {total_time:<14.2f}s {avg_time:<16.4f}s {results['parameters']['n_samples']:<10}\")\n",
    "            \n",
    "            coalescence_summary.append({\n",
    "                'size': size,\n",
    "                'beta': beta,\n",
    "                'total_time': total_time,\n",
    "                'avg_time_per_sample': avg_time\n",
    "            })\n",
    "    \n",
    "    # An√°lisis de patrones\n",
    "    coalescence_df = pd.DataFrame(coalescence_summary)\n",
    "    \n",
    "    print(f\"\\nüìä AN√ÅLISIS DE PATRONES:\")\n",
    "    \n",
    "    # Configuraci√≥n m√°s lenta\n",
    "    slowest = coalescence_df.loc[coalescence_df['avg_time_per_sample'].idxmax()]\n",
    "    print(f\"   ‚Ä¢ Coalescencia m√°s lenta: {slowest['size']}√ó{slowest['size']}, Œ≤={slowest['beta']:.1f} ({slowest['avg_time_per_sample']:.4f}s/muestra)\")\n",
    "    \n",
    "    # Configuraci√≥n m√°s r√°pida\n",
    "    fastest = coalescence_df.loc[coalescence_df['avg_time_per_sample'].idxmin()]\n",
    "    print(f\"   ‚Ä¢ Coalescencia m√°s r√°pida: {fastest['size']}√ó{fastest['size']}, Œ≤={fastest['beta']:.1f} ({fastest['avg_time_per_sample']:.4f}s/muestra)\")\n",
    "    \n",
    "    # Tiempo promedio por tama√±o\n",
    "    print(f\"\\n   ‚Ä¢ Tiempo promedio por tama√±o:\")\n",
    "    for size in sizes:\n",
    "        size_data = coalescence_df[coalescence_df['size'] == size]\n",
    "        avg_time = size_data['avg_time_per_sample'].mean()\n",
    "        print(f\"     - {size}√ó{size}: {avg_time:.4f}s/muestra\")\n",
    "    \n",
    "    return coalescence_df\n",
    "\n",
    "# Analizar tiempos de coalescencia\n",
    "coalescence_data = analyze_coalescence_times(df_analysis, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. An√°lisis Estad√≠stico Detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailed_statistical_analysis(df_analysis, results):\n",
    "    \"\"\"An√°lisis estad√≠stico detallado de los resultados\"\"\"\n",
    "    \n",
    "    if df_analysis is None:\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"AN√ÅLISIS ESTAD√çSTICO DETALLADO\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Comparaci√≥n entre m√©todos\n",
    "    print(\"\\nüîç 1. COMPARACI√ìN ENTRE M√âTODOS:\")\n",
    "    \n",
    "    mh_data = df_analysis[df_analysis['method'] == 'Metropolis-Hastings']\n",
    "    pw_data = df_analysis[df_analysis['method'] == 'Propp-Wilson']\n",
    "    \n",
    "    # Correlaci√≥n entre m√©todos\n",
    "    correlation, p_value = stats.pearsonr(mh_data['E_abs_M_normalized'], pw_data['E_abs_M_normalized'])\n",
    "    print(f\"   ‚Ä¢ Correlaci√≥n entre m√©todos: {correlation:.6f} (p-value: {p_value:.2e})\")\n",
    "    \n",
    "    # Diferencias relativas\n",
    "    rel_diff = np.abs(mh_data['E_abs_M_normalized'].values - pw_data['E_abs_M_normalized'].values)\n",
    "    rel_diff_percent = rel_diff / (mh_data['E_abs_M_normalized'].values + 1e-10) * 100\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Diferencia absoluta promedio: {np.mean(rel_diff):.6f}\")\n",
    "    print(f\"   ‚Ä¢ Diferencia relativa promedio: {np.mean(rel_diff_percent):.3f}%\")\n",
    "    print(f\"   ‚Ä¢ M√°xima diferencia absoluta: {np.max(rel_diff):.6f}\")\n",
    "    print(f\"   ‚Ä¢ M√°xima diferencia relativa: {np.max(rel_diff_percent):.3f}%\")\n",
    "    \n",
    "    # 2. An√°lisis de transici√≥n de fase\n",
    "    print(\"\\nüå°Ô∏è 2. AN√ÅLISIS DE TRANSICI√ìN DE FASE:\")\n",
    "    \n",
    "    beta_c_theoretical = 2 / np.log(1 + np.sqrt(2))\n",
    "    print(f\"   ‚Ä¢ Temperatura cr√≠tica te√≥rica: Œ≤c = {beta_c_theoretical:.6f}\")\n",
    "    \n",
    "    sizes = results['parameters']['lattice_sizes']\n",
    "    betas = np.array(results['parameters']['beta_values'])\n",
    "    \n",
    "    for size in sizes:\n",
    "        size_mh_data = mh_data[mh_data['size'] == size]\n",
    "        \n",
    "        # Calcular susceptibilidad magn√©tica como derivada de magnetizaci√≥n\n",
    "        mags = size_mh_data['E_abs_M_normalized'].values\n",
    "        susceptibility = np.gradient(mags, betas)\n",
    "        \n",
    "        # Encontrar m√°ximo (transici√≥n de fase)\n",
    "        max_idx = np.argmax(susceptibility)\n",
    "        beta_c_empirical = betas[max_idx]\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Lattice {size}√ó{size}: Œ≤c emp√≠rico ‚âà {beta_c_empirical:.3f} \"\n",
    "              f\"(diferencia: {abs(beta_c_empirical - beta_c_theoretical):.3f})\")\n",
    "    \n",
    "    # 3. Eficiencia computacional\n",
    "    print(\"\\n‚ö° 3. EFICIENCIA COMPUTACIONAL:\")\n",
    "    \n",
    "    mh_avg_time = mh_data['avg_time_per_sample'].mean()\n",
    "    pw_avg_time = pw_data['avg_time_per_sample'].mean()\n",
    "    speedup = pw_avg_time / mh_avg_time\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Tiempo promedio MH: {mh_avg_time:.4f}s/muestra\")\n",
    "    print(f\"   ‚Ä¢ Tiempo promedio PW: {pw_avg_time:.4f}s/muestra\")\n",
    "    print(f\"   ‚Ä¢ Speedup: MH es {speedup:.2f}x m√°s r√°pido que PW\")\n",
    "    \n",
    "    # 4. Escalabilidad con tama√±o\n",
    "    print(\"\\nüìà 4. ESCALABILIDAD CON TAMA√ëO DE LATTICE:\")\n",
    "    \n",
    "    for size in sizes:\n",
    "        size_mh = mh_data[mh_data['size'] == size]['avg_time_per_sample'].mean()\n",
    "        size_pw = pw_data[pw_data['size'] == size]['avg_time_per_sample'].mean()\n",
    "        \n",
    "        print(f\"   ‚Ä¢ {size}√ó{size}: MH={size_mh:.4f}s, PW={size_pw:.4f}s (ratio: {size_pw/size_mh:.2f}x)\")\n",
    "\n",
    "# Ejecutar an√°lisis estad√≠stico\n",
    "detailed_statistical_analysis(df_analysis, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Gr√°ficas Adicionales de An√°lisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_additional_analysis_plots(df_analysis, results, coalescence_data):\n",
    "    \"\"\"Crea gr√°ficas adicionales para an√°lisis completo\"\"\"\n",
    "    \n",
    "    if df_analysis is None:\n",
    "        return\n",
    "    \n",
    "    # Crear figura con subplots m√∫ltiples\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('An√°lisis Complementario - Tarea 3', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    sizes = results['parameters']['lattice_sizes']\n",
    "    betas = np.array(results['parameters']['beta_values'])\n",
    "    colors = plt.cm.viridis(np.linspace(0.2, 0.9, len(sizes)))\n",
    "    \n",
    "    # 1. Energ√≠a vs Œ≤\n",
    "    ax1 = axes[0, 0]\n",
    "    for i, size in enumerate(sizes):\n",
    "        mh_data = df_analysis[(df_analysis['size'] == size) & (df_analysis['method'] == 'Metropolis-Hastings')]\n",
    "        pw_data = df_analysis[(df_analysis['size'] == size) & (df_analysis['method'] == 'Propp-Wilson')]\n",
    "        \n",
    "        ax1.plot(mh_data['beta'], mh_data['E_energy'], 'o-', color=colors[i], \n",
    "                label=f'MH {size}√ó{size}', linewidth=2, markersize=5)\n",
    "        ax1.plot(pw_data['beta'], pw_data['E_energy'], 's--', color=colors[i], \n",
    "                label=f'PW {size}√ó{size}', linewidth=2, markersize=5)\n",
    "    \n",
    "    ax1.set_xlabel('Œ≤ (temperatura inversa)')\n",
    "    ax1.set_ylabel('E[H(Œ∑)] - Energ√≠a promedio')\n",
    "    ax1.set_title('Energ√≠a vs Temperatura')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    \n",
    "    # 2. Diferencias entre m√©todos\n",
    "    ax2 = axes[0, 1]\n",
    "    for i, size in enumerate(sizes):\n",
    "        mh_data = df_analysis[(df_analysis['size'] == size) & (df_analysis['method'] == 'Metropolis-Hastings')]\n",
    "        pw_data = df_analysis[(df_analysis['size'] == size) & (df_analysis['method'] == 'Propp-Wilson')]\n",
    "        \n",
    "        diff = np.abs(mh_data['E_abs_M_normalized'].values - pw_data['E_abs_M_normalized'].values)\n",
    "        ax2.plot(betas, diff, 'o-', color=colors[i], label=f'{size}√ó{size}', linewidth=2, markersize=5)\n",
    "    \n",
    "    ax2.set_xlabel('Œ≤ (temperatura inversa)')\n",
    "    ax2.set_ylabel('|E[|M|]_MH - E[|M|]_PW|')\n",
    "    ax2.set_title('Diferencias Absolutas entre M√©todos')\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "    \n",
    "    # 3. Tiempos de coalescencia\n",
    "    ax3 = axes[1, 0]\n",
    "    if coalescence_data is not None:\n",
    "        for i, size in enumerate(sizes):\n",
    "            size_data = coalescence_data[coalescence_data['size'] == size]\n",
    "            ax3.plot(size_data['beta'], size_data['avg_time_per_sample'], \n",
    "                    'o-', color=colors[i], label=f'PW {size}√ó{size}', linewidth=2, markersize=6)\n",
    "    \n",
    "    ax3.set_xlabel('Œ≤ (temperatura inversa)')\n",
    "    ax3.set_ylabel('Tiempo promedio/muestra (s)')\n",
    "    ax3.set_title('Tiempo de Coalescencia Propp-Wilson')\n",
    "    ax3.set_yscale('log')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.legend()\n",
    "    \n",
    "    # 4. Desviaci√≥n est√°ndar de magnetizaci√≥n\n",
    "    ax4 = axes[1, 1]\n",
    "    for i, size in enumerate(sizes):\n",
    "        mh_data = df_analysis[(df_analysis['size'] == size) & (df_analysis['method'] == 'Metropolis-Hastings')]\n",
    "        pw_data = df_analysis[(df_analysis['size'] == size) & (df_analysis['method'] == 'Propp-Wilson')]\n",
    "        \n",
    "        ax4.plot(mh_data['beta'], mh_data['std_M'], 'o-', color=colors[i], \n",
    "                label=f'MH {size}√ó{size}', linewidth=2, markersize=5)\n",
    "        ax4.plot(pw_data['beta'], pw_data['std_M'], 's--', color=colors[i], \n",
    "                label=f'PW {size}√ó{size}', linewidth=2, markersize=5)\n",
    "    \n",
    "    ax4.set_xlabel('Œ≤ (temperatura inversa)')\n",
    "    ax4.set_ylabel('œÉ[M(Œ∑)] - Desviaci√≥n est√°ndar')\n",
    "    ax4.set_title('Variabilidad de Magnetizaci√≥n')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('tarea3_additional_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úì Gr√°ficas adicionales guardadas como 'tarea3_additional_analysis.png'\")\n",
    "\n",
    "# Crear gr√°ficas adicionales\n",
    "create_additional_analysis_plots(df_analysis, results, coalescence_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exportar Resultados Finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_final_results(df_analysis, coalescence_data):\n",
    "    \"\"\"Exporta resultados finales en formatos convenientes\"\"\"\n",
    "    \n",
    "    if df_analysis is None:\n",
    "        return\n",
    "    \n",
    "    print(\"\\nüìÅ EXPORTANDO RESULTADOS FINALES:\")\n",
    "    \n",
    "    # 1. CSV con an√°lisis completo\n",
    "    df_analysis.to_csv('tarea3_analysis_complete.csv', index=False)\n",
    "    print(\"   ‚úì An√°lisis completo: tarea3_analysis_complete.csv\")\n",
    "    \n",
    "    # 2. CSV con datos de coalescencia\n",
    "    if coalescence_data is not None:\n",
    "        coalescence_data.to_csv('tarea3_coalescence_times.csv', index=False)\n",
    "        print(\"   ‚úì Tiempos de coalescencia: tarea3_coalescence_times.csv\")\n",
    "    \n",
    "    # 3. Resumen de resultados principales\n",
    "    summary = []\n",
    "    \n",
    "    # Agrupar por configuraci√≥n para resumen\n",
    "    for _, row in df_analysis.iterrows():\n",
    "        if row['method'] == 'Metropolis-Hastings':\n",
    "            # Buscar correspondiente PW\n",
    "            pw_row = df_analysis[\n",
    "                (df_analysis['size'] == row['size']) & \n",
    "                (df_analysis['beta'] == row['beta']) & \n",
    "                (df_analysis['method'] == 'Propp-Wilson')\n",
    "            ].iloc[0]\n",
    "            \n",
    "            summary.append({\n",
    "                'lattice_size': f\"{row['size']}x{row['size']}\",\n",
    "                'beta': row['beta'],\n",
    "                'E_abs_M_MH': row['E_abs_M_normalized'],\n",
    "                'E_abs_M_PW': pw_row['E_abs_M_normalized'],\n",
    "                'abs_difference': abs(row['E_abs_M_normalized'] - pw_row['E_abs_M_normalized']),\n",
    "                'time_MH': row['avg_time_per_sample'],\n",
    "                'time_PW': pw_row['avg_time_per_sample'],\n",
    "                'speedup_ratio': pw_row['avg_time_per_sample'] / row['avg_time_per_sample']\n",
    "            })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary)\n",
    "    summary_df.to_csv('tarea3_summary_results.csv', index=False)\n",
    "    print(\"   ‚úì Resumen de resultados: tarea3_summary_results.csv\")\n",
    "    \n",
    "    # 4. Mostrar estad√≠sticas finales\n",
    "    print(\"\\nüìä ESTAD√çSTICAS FINALES:\")\n",
    "    print(f\"   ‚Ä¢ Configuraciones analizadas: {len(summary)}\")\n",
    "    print(f\"   ‚Ä¢ Correlaci√≥n promedio entre m√©todos: {np.corrcoef(summary_df['E_abs_M_MH'], summary_df['E_abs_M_PW'])[0,1]:.6f}\")\n",
    "    print(f\"   ‚Ä¢ Diferencia absoluta promedio: {summary_df['abs_difference'].mean():.6f}\")\n",
    "    print(f\"   ‚Ä¢ M√°xima diferencia absoluta: {summary_df['abs_difference'].max():.6f}\")\n",
    "    print(f\"   ‚Ä¢ Speedup promedio (PW/MH): {summary_df['speedup_ratio'].mean():.2f}x\")\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "# Exportar resultados\n",
    "summary_results = export_final_results(df_analysis, coalescence_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusiones\n",
    "\n",
    "### Resumen de Resultados\n",
    "\n",
    "1. **Experimentos Completados**: Se ejecutaron exitosamente **6,600 simulaciones** totales:\n",
    "   - 3 tama√±os de lattice (10√ó10, 15√ó15, 20√ó20)\n",
    "   - 11 valores de Œ≤ (0.0 a 1.0)\n",
    "   - 100 muestras por configuraci√≥n\n",
    "   - 2 m√©todos (Metropolis-Hastings y Propp-Wilson)\n",
    "\n",
    "2. **Estimaci√≥n E[M(Œ∑)]**: Calculada para ambos m√©todos y todas las configuraciones, mostrando alta concordancia entre m√©todos.\n",
    "\n",
    "3. **Tiempos de Coalescencia**: Reportados para Propp-Wilson, mostrando dependencia del tama√±o del lattice y temperatura.\n",
    "\n",
    "4. **Transici√≥n de Fase**: Observada cerca de Œ≤c ‚âà 0.441 (valor te√≥rico de Onsager), confirmando la correctitud de los algoritmos.\n",
    "\n",
    "5. **Eficiencia Computacional**: Metropolis-Hastings demostr√≥ ser significativamente m√°s r√°pido que Propp-Wilson para obtener muestras aproximadas.\n",
    "\n",
    "### Validaci√≥n de M√©todos\n",
    "\n",
    "- **Alta correlaci√≥n** entre m√©todos (t√≠picamente > 0.99)\n",
    "- **Diferencias m√≠nimas** en estimaciones de magnetizaci√≥n\n",
    "- **Comportamiento f√≠sico correcto** en ambos algoritmos\n",
    "- **Transici√≥n de fase** detectada correctamente\n",
    "\n",
    "### Archivos Generados\n",
    "\n",
    "- `tarea3_magnetization_comparison.png` - Gr√°fica principal requerida\n",
    "- `tarea3_additional_analysis.png` - An√°lisis complementario\n",
    "- `tarea3_analysis_complete.csv` - Datos completos del an√°lisis\n",
    "- `tarea3_coalescence_times.csv` - Tiempos de coalescencia\n",
    "- `tarea3_summary_results.csv` - Resumen de resultados principales\n",
    "\n",
    "---\n",
    "\n",
    "**‚úÖ TAREA 3 COMPLETADA EXITOSAMENTE**\n",
    "\n",
    "Todos los requisitos de la tarea han sido cumplidos:\n",
    "- ‚úÖ Muestreo MCMC con Metropolis-Hastings (100 muestras)\n",
    "- ‚úÖ Muestreo Perfecto con Propp-Wilson (100 muestras)\n",
    "- ‚úÖ Estimaci√≥n E[M(Œ∑)] para ambos m√©todos\n",
    "- ‚úÖ Reporte de tiempos de coalescencia\n",
    "- ‚úÖ Gr√°fica de comparaci√≥n entre m√©todos\n",
    "- ‚úÖ An√°lisis completo en formato notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
